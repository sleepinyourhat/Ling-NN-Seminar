{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2 Exercise: (k-)Nearest Neighbors and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick warning: If you're new to working with large(ish) datasets in iPython/Jupyter, be careful about print statements. If you accidentally print out the entire dataset (or something of similar size), you may not be able to stop the command from running, and it can easily take up enough time and space to stall the UI. The easiest way out of this is to simply refresh the page, but you may loose some work that way.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load the Stanford Sentiment Treebank. Download it from here: [the train/dev/test Stanford Sentiment Treebank distribution](http://nlp.stanford.edu/sentiment/trainDevTestTrees_PTB.zip), unzip it, and put the resulting folder in the same directory as this notebook. (If you want to put it somewhere else, change `sst_home` below.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sst_home = './trees'\n",
    "\n",
    "import re\n",
    "import random\n",
    "\n",
    "# Let's do 2-way positive/negative classification instead of 5-way\n",
    "easy_label_map = {0:0, 1:0, 2:None, 3:1, 4:1}\n",
    "\n",
    "def load_sst_data(path):\n",
    "    data = []\n",
    "    with open(path) as f:\n",
    "        for i, line in enumerate(f): \n",
    "            example = {}\n",
    "            example['label'] = easy_label_map[int(line[1])]\n",
    "            if example['label'] is None:\n",
    "                continue\n",
    "            \n",
    "            # Strip out the parse information and the phrase labels---we don't need those here\n",
    "            text = re.sub(r'\\s*(\\(\\d)|(\\))\\s*', '', line)\n",
    "            example['text'] = text[1:]\n",
    "            data.append(example)\n",
    "\n",
    "    random.shuffle(data)\n",
    "    return data\n",
    "     \n",
    "training_set = load_sst_data(sst_home + '/train.txt')\n",
    "dev_set = load_sst_data(sst_home + '/dev.txt')\n",
    "test_set = load_sst_data(sst_home + '/test.txt')\n",
    "\n",
    "# Because these models can be very slow to test, we'll only use tiny test/dev sets here.\n",
    "# Note: For a real paper, you should always use the full test/dev sets.\n",
    "\n",
    "dev_set = dev_set[0:100]\n",
    "test_set = test_set[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Feature Engineering and Nearest Negihbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's write a function to convert these sentences into feature vectors. The function template here simply extracts three useless (?) dummy features:\n",
    "\n",
    "- The number of characters in the review.\n",
    "- The first letter in the review.\n",
    "- Whether the letters 'th' appear in the review.\n",
    "\n",
    "This function depends upon a simple dictionary trick that allows us to reason about features by name rather than by index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def feature_function(datasets):\n",
    "    '''Annotates datasets with feature vectors.'''\n",
    "    \n",
    "    feature_names = set()\n",
    "    for dataset in datasets:\n",
    "        for example in dataset:\n",
    "            example['features'] = collections.defaultdict(float)\n",
    "            \n",
    "            # Extract features (by name) for one example\n",
    "            example['features']['dummy_char_count'] = len(example['text'])\n",
    "            example['features']['dummy_first_char_' + example['text'][0]] = 1\n",
    "            example['features']['dummy_contains_th'] = 'th' in example['text']\n",
    "    \n",
    "            feature_names.update(example['features'].keys())\n",
    "                            \n",
    "    # By now, we know what all the features will be, so we can\n",
    "    # assign indices to them.\n",
    "    feature_indices = dict(zip(feature_names, range(len(feature_names))))\n",
    "    indices_to_features = {v: k for k, v in feature_indices.items()}\n",
    "    dim = len(feature_indices)\n",
    "    \n",
    "    # Now we create actual vectors from those indices.\n",
    "    for dataset in datasets:\n",
    "        for example in dataset:\n",
    "            example['vector'] = np.zeros((dim))\n",
    "            for feature in example['features']:\n",
    "                example['vector'][feature_indices[feature]] = example['features'][feature]\n",
    "    return indices_to_features\n",
    "    \n",
    "indices_to_features = feature_function([training_set, dev_set, test_set])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I put together a simple nearest-neighbors classifier based on Euclidean distance. It doesn't have any special tricks for speed, but it does the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nearest_neighbor_classifier(example, training_set):\n",
    "    best_distance = None\n",
    "    label = None\n",
    "    distance_label_pairs = []\n",
    "    \n",
    "    # Calculate the distances\n",
    "    for training_example in training_set:\n",
    "        difference = example['vector'] - training_example['vector']\n",
    "        distance = np.sqrt(np.sum(np.square(difference)))\n",
    "        distance_label_pairs.append((distance, training_example['label']))\n",
    "        \n",
    "    # Sort the pairs by distance\n",
    "    sorted_pairs = sorted(distance_label_pairs, key=lambda example: example[0])\n",
    "    return sorted_pairs[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how it's called. It returns a label (0 for negative, 1 for positive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_neighbor_classifier(dev_set[0], training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a simple function to evaluate a classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_classifier(classifier, eval_set):\n",
    "    correct = 0\n",
    "    for example in eval_set:\n",
    "        hypothesis = classifier(example)\n",
    "        if hypothesis == example['label']:\n",
    "            correct += 1\n",
    "    return correct / float(len(eval_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation tools like this one expect a trained classifier, which should act like a simple function over test examples with no other arguments, so we'll add a wrapper that incorporates the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trained_nearest_neighbor_classifier(example):\n",
    "    return nearest_neighbor_classifier(example, training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This runs the primary evaluation. It'll return accuracy (%). The base model should get 47%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47\n"
     ]
    }
   ],
   "source": [
    "print evaluate_classifier(trained_nearest_neighbor_classifier, dev_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try to create a function that implements *k*-nearest neighbor classification. You're welcome to use the code from nearest_neighbor_classifier above as starter code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def k_nearest_neighbor_classifier(example, training_set, k):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's evaluate it, specifying a particular value of `k` when we do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48\n"
     ]
    }
   ],
   "source": [
    "def trained_k_nearest_neighbor_classifier(example):\n",
    "    return k_nearest_neighbor_classifier(example, training_set, k=2)\n",
    "\n",
    "print evaluate_classifier(trained_k_nearest_neighbor_classifier, dev_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What value of `k` works best? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
